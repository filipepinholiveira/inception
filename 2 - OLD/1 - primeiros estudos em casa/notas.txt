
RESUMO: 

O mecanismo Docker é o componente principal do Docker. É uma ferramenta leve de tempo de execução e empacotamento que agrupa seu aplicativo 
e suas dependências em um único pacote, chamado contêiner. 

O mecanismo Docker inclui o daemon Docker, que é um processo em segundo plano que gerencia contêineres Docker, e o cliente Docker, 
que é uma ferramenta de linha de comando que permite interagir com o daemon Docker.

Veja como funciona o mecanismo Docker:

    Você escreve um Dockerfile, que é um arquivo de texto que contém as instruções para construir uma imagem Docker. 
    Uma imagem Docker é um pacote executável leve e independente que inclui tudo o que é necessário para executar um software, 
    incluindo o código do aplicativo, bibliotecas, dependências e tempo de execução.
    Você usa o cliente Docker para construir a imagem Docker executando o comando docker build e especificando o caminho para o Dockerfile. 
    O daemon Docker lê as instruções no Dockerfile e constrói a imagem.
    Depois que a imagem for criada, você poderá usar o cliente Docker para executar a imagem como um contêiner usando o comando docker run. 
    O daemon Docker cria um contêiner a partir da imagem e executa o aplicativo dentro do contêiner.
    O mecanismo Docker fornece um ambiente seguro e isolado para a execução do aplicativo e também gerencia recursos como CPU, 
    memória e armazenamento para o contêiner.
    Você pode usar o cliente Docker para visualizar, parar e gerenciar os contêineres em execução no seu sistema. 
    Você também pode usar o cliente Docker para enviar a imagem do Docker para um registro, como o Docker Hub, para que ela possa 
    ser compartilhada com outras pessoas.






Agora Depois que entendemos o que é o Docker e como ele funciona agora, vamos apresentá-lo ao arquivo Dockerfile e Docker-compose.

    Um arquivo Dockerfile é um arquivo de texto que contém as instruções para a construção de uma imagem Docker. 
    Ele especifica a imagem base a ser usada, as dependências e o software a instalar e quaisquer outras configurações 
    ou scripts necessários para configurar o ambiente para a execução do aplicativo.

    Um arquivo Docker Compose é um arquivo YAML que define como vários contêineres Docker devem ser configurados e executados. Ele permite que você defina os serviços que compõem seu aplicativo e, em seguida, inicie e interrompa todos os contêineres com um único comando.

Aqui estão algumas diferenças importantes entre um arquivo Dockerfile e um arquivo Docker Compose:

    Finalidade: Um Dockerfile é usado para criar uma única imagem Docker, enquanto um arquivo Docker Compose é usado para definir e executar vários contêineres Docker como um único aplicativo.
    Formato: Um Dockerfile é um arquivo de texto simples com um formato e sintaxe específicos, enquanto um arquivo Docker Compose é escrito em YAML.
    Escopo: Um Dockerfile está focado na construção de uma única imagem, enquanto um arquivo Docker Compose é focado em definir e executar vários contêineres como um único aplicativo.
    Comandos: Um Dockerfile usa comandos específicos, como FROM,, , - A , de cima para o que sobre o que sobre o que sobre, , sobre o que sobre o que sobre, , sobre o RUN, e CMD, para definir as instruções para construir a imagem. Um arquivo Docker Compose usa comandos diferentes, como services,, , - A , de cima para o que sobre o que sobre o que sobre, , sobre o que sobre o que sobre, , sobre o volumes, e networks, para definir os recipientes e como eles devem ser configurados e executados.

    Aqui está uma breve explicação de algumas das chaves mencionadas acima.

    Este FROMé um comando que é usado em um Dockerfile para especificar a imagem base a usar como ponto de partida para a construção da imagem Docker. A imagem base fornece as camadas fundamentais para a imagem e você pode adicionar camadas adicionais em cima dela para personalizar a imagem para suas necessidades específicas.
    Este RUNé um comando que é usado em um Dockerfile para executar um comando no terminal do contêiner. É normalmente usado para instalar software ou bibliotecas que são necessárias para o aplicativo.
    Este CMDé um comando que é usado em um Dockerfile para especificar o comando padrão que deve ser executado quando um contêiner é iniciado a partir da imagem. Ele é usado para especificar o comando principal que o contêiner deve executar quando ele é iniciado.
    Esta servicesé uma chave em um arquivo Docker Compose que é usado para definir os serviços que compõem o seu aplicativo. Um serviço é um contêiner que executa um aplicativo ou componente específico do seu aplicativo.
    Esta volumesé uma chave em um arquivo Docker Compose que é usado para definir o armazenamento persistente para o seu aplicativo. Um volume é um pedaço de armazenamento que é anexado a um contêiner e é usado para armazenar dados que devem persistir mesmo quando o recipiente é parado ou removido.
    Esta networksé uma chave em um arquivo Docker Compose que é usado para definir as redes que os contêineres devem ser conectados à rede A é uma rede virtual que é usada para conectar contêineres e permitir que eles se comuniquem entre si.

Quais são os comandos mais comuns usados no docker?

    docker build: Usado para construir uma imagem do Docker a partir de um Dockerfile.
    docker run: Usado para executar um contêiner Docker baseado em uma imagem Docker.
    docker pull: Usado para puxar uma imagem Docker de um registro, como o Docker Hub.
    docker push: Usado para empurrar uma imagem Docker para um registro.
    docker ps: Usado para listar os contêineres Docker em execução em um sistema.
    docker stop: Usado para parar um recipiente Docker em execução.
    docker rm: Usado para remover um recipiente Docker.
    docker rmi: Usado para remover uma imagem do Docker.
    docker exec: Usado para executar um comando em um contêiner Docker em execução.
    docker logs: Usado para visualizar os logs para um recipiente Docker.





COMPOSE DOCKER

O Docker Compose é uma ferramenta para definir e executar aplicativos Docker multi-container. 
Com o Compose, você usa um arquivo YAML para configurar os serviços do aplicativo. 
Em seguida, usando um único comando, você pode criar e iniciar todos os serviços a partir de sua configuração.

O uso do Docker Compose pode simplificar o processo de gerenciamento de aplicativos de vários contêineres, 
permitindo que você defina todos os seus serviços em um único local e inicie e interrompa-os facilmente. 
Também facilita a escalabilidade do aplicativo, permitindo que você aumente ou diminua o número de réplicas de um serviço.


Quais são os comandos mais comuns usados no docker-compose?

    up: Criar e iniciar recipientes
    downParar e remover contêineres, redes, imagens e volumes
    start: Iniciar os contentores existentes
    stop: Pare de em funcionamento de contentores
    restart: Reinicialização de contêineres de corrida
    build: Construir imagens
    ps: Lista de recipientes
    logs: Ver a saída dos contentores
    exec: Executar um comando em um contêiner em execução
    pull: Puxe imagens de um registro
    push: Empurre imagens para um registro




O que são DOCKER NETWORKS

No Docker, uma rede é uma rede de software virtual que conecta contêineres Docker. 
Ele permite que os contêineres se comuniquem entre si e com o mundo exterior, e fornece uma camada adicional 
de abstração sobre a infraestrutura de rede subjacente.

Existem vários tipos de redes que você pode criar no Docker, incluindo:

    Ponte: Uma rede de ponte é o tipo de rede padrão quando você instala o Docker. 
    Ele permite que os contêineres se comuniquem entre si e com a máquina hospedeira, mas não fornece acesso ao mundo exterior.
    Host: Uma rede de host usa a pilha de rede da máquina host e não fornece isolamento entre o host e o contêiner.
    Sobreposição: Uma rede de sobreposição permite que contêineres executados em diferentes hosts do Docker se comuniquem entre si.
    Macvlan: Uma rede Macvlan permite que um contêiner tenha seu próprio endereço IP na mesma sub-rede que a máquina host.

Você pode criar e gerenciar redes usando o docker network- Comando. Por exemplo, 
para criar uma nova rede de pontes, você pode usar o seguinte comando:

docker network create my-network

    recursos para rede docker : https://www.youtube.com/watch?v-bKFMS5C4CG0


O que são DOCKER VOLUMES

No Docker, um volume é um local de armazenamento persistente que é usado para armazenar dados de um contêiner. 
Os volumes são usados para persistir os dados de um contêiner mesmo após o estoque ser excluído e podem ser compartilhados entre os contêineres.

Existem dois tipos de volumes no Docker:

    Montagem vinculante: Uma montagem de ligação é um arquivo ou diretório na máquina host que é montado em um contêiner. 
    Quaisquer alterações feitas na montagem de bind são refletidas na máquina host e em quaisquer outros contêineres 
    que montam o mesmo arquivo ou diretório.
    Volume nomeado: Um volume nomeado é um volume gerenciado que é criado e gerenciado pelo Docker. 
    Ele é armazenado em um local específico na máquina host e não está vinculado a um arquivo ou diretório específico no host. 
    Os volumes nomeados são úteis para armazenar dados que precisam ser compartilhados entre contêineres, 
    pois podem ser facilmente conectados e desapegados de contêineres.

Você pode criar e gerenciar volumes usando o docker volume- Comando. Por exemplo, para criar um novo volume nomeado, você pode usar o seguinte comando:

docker volume create my-volume

Para montar um volume em um recipiente, você pode usar o -vsinalizar ao iniciar o recipiente. Por exemplo:

docker run -v my-volume:/var/lib/mysql mysql

Este comando iniciará um contêiner executando o mysqlimagem e montar o my-volumeO volume em /var/lib/mysqldentro do recipiente. 
Quaisquer dados gravados neste local no contêiner serão persistentes no volume, mesmo que o contêiner seja excluído.

Você também pode usar o Docker Compose para criar e gerenciar volumes. Em um arquivo Compose, você pode definir um volume 
e anexá-lo a um serviço. Por exemplo:

version: '3'
services:
  db:
    image: mysql
    volumes:
      - db-data:/var/lib/mysql
volumes:
  db-data:

Este arquivo Compose define a db-datavolume e prende-o ao dbO serviço em /var/lib/mysql- A . (í a , , , , , í , . 
Quaisquer dados gravados neste local no contêiner serão persistentes no volume.



PARTE DE MANDATORY
Mariadb (B)

O MariaDB é um sistema de gerenciamento de banco de dados relacional livre e de código aberto (RDBMS) 
que é amplamente utilizado como substituto do MySQL. Seu nome é uma homenagem à filha do desenvolvedor, Maria, 
e é projetado para ser uma alternativa orientada para a comunidade para o MySQL, com foco na simplicidade, colaboração 
e compatibilidade com outros sistemas de banco de dados.

O MariaDB inclui vários recursos e melhorias adicionais em relação ao MySQL, incluindo melhor desempenho, 
segurança aprimorada e suporte para novos mecanismos de armazenamento e tipos de dados. 
Também é ativamente desenvolvido e apoiado por uma grande e ativa comunidade de usuários e desenvolvedores.

    Parte da instalação:

    PullTradução debian:buster(A nossa imagem base)
    atualizar o nosso gerenciador de pacotes apt-get update -y
    instalar o servidor mariadb apt-get install mariadb-server -y
    ir para /etc/mysql/mariadb.conf.d/50-server.cnf e mudar a linha 28 de bind-address = 127.0.0.1para bind-address = 0.0.0.0
    para qualquer rede pode se conectar ao nosso Mariadb
    service mysql start
    criar o nosso banco de dados e o nosso usuário e dar-lhe o acesso ao banco de dados, em seguida, FLUSH PRIVILEGES

    scripts parte:

#db_name = Database Name
#db_user = User
#db_pwd = User Password

echo "CREATE DATABASE IF NOT EXISTS $db_name ;" > db1.sql
echo "CREATE USER IF NOT EXISTS '$db_user'@'%' IDENTIFIED BY '$db_pwd' ;" >> db1.sql
echo "GRANT ALL PRIVILEGES ON $db_name.* TO '$db_user'@'%' ;" >> db1.sql
echo "ALTER USER 'root'@'localhost' IDENTIFIED BY '12345' ;" >> db1.sql
echo "FLUSH PRIVILEGES;" >> db1.sql

mysql < db1.sql

para manter o contêiner funcionando, execute este comando em CMD no seu Dockerfile /usr/bin/mysqld_safe

mysqld_safeé normalmente usado para iniciar o servidor MySQL quando o sistema está inicializando, e também é usado para iniciar 
e parar o servidor MySQL manualmente
Wordpress (Palav

WordPress é um sistema de gerenciamento de conteúdo (CMS) baseado em PHP e MySQL. 
É uma plataforma de código aberto que é amplamente utilizada para a construção de sites, blogs e aplicativos. 
Com o WordPress, os usuários podem facilmente criar e gerenciar seus próprios sites sem a necessidade de habilidades técnicas avançadas. 
É conhecida por sua simplicidade e flexibilidade, tornando-se uma escolha popular para desenvolvedores iniciantes e experientes. 
O WordPress tem uma grande comunidade de usuários e desenvolvedores que contribuem para a plataforma, 
o que levou ao desenvolvimento de uma ampla gama de temas, plugins e outras ferramentas que podem ser usadas para 
ampliar a funcionalidade dos sites WordPress.

    Antes de mergulharmos na peça de instalação, você precisa saber sobre o fastCGI porque é bastante importador no nosso caso.

Rápido de ?

FastCGI (Fast Common Gateway Interface) é um protocolo que permite que servidores web se comuniquem com aplicativos da Web, 
como scripts PHP. Ele é projetado para permitir que os servidores da Web executem scripts de uma maneira mais eficiente 
do que os protocolos tradicionais CGI (Common Gateway Interface), que envolvem o início de um novo processo para executar cada script.

PHP-FPM (FastCGI Process Manager) é uma implementação do protocolo FastCGI projetado especificamente para uso com PHP. 
Ele funciona iniciando um conjunto de processos de trabalho que são responsáveis pela execução de scripts PHP. 
Quando um servidor web recebe uma solicitação para um script PHP, ele passa a solicitação para um dos processos de trabalho, 
que executa o script e retorna o resultado para o servidor web. Isso permite que os scripts PHP sejam executados de forma mais eficiente, 
pois os processos de trabalho podem ser reutilizados para várias solicitações.

O PHP-FPM é frequentemente usado como uma alternativa ao mod_php, que é um módulo Apache que incorpora 
o interpretador PHP diretamente no servidor web Apache. O uso do PHP-FPM pode melhorar o desempenho 
e a escalabilidade dos scripts PHP, pois permite que o servidor web e o PHP sejam executados em processos separados. 
Ele também permite um controle mais retecido sobre o ambiente PHP, pois diferentes pools de processos de trabalho 
podem ser configurados com configurações diferentes.

    Parte da instalação:

    puxar debian:buster(A nossa imagem base)
    atualizar o nosso gerenciador de pacotes apt-get -y update& & & apt-get -y upgrade& & & apt update -y& & & apt upgrade -y
    apt installphp-fpmphp-mysql -y& & & apt install curl -y

O primeiro comando instala o php-fpmE a php-mysqlEmpacotos. php-fpm(FastCGI Process Manager) é uma implementação do FastCGI 
que é usado para executar scripts PHP, e php-mysqlé uma extensão PHP que permite que o PHP se comunique com bancos de dados MySQL.

O terceiro comando instala o curlpacote, que é uma ferramenta de linha de comando para transferir dados usando vários protocolos de rede, 
incluindo HTTP, HTTPS e FTP.

Minha fonte de informação https://developer.wordpress.org/cli/commands/core/

    script parte:

#!/bin/bash

# create directory to use in nginx container later and also to setup the wordpress conf
mkdir /var/www/
mkdir /var/www/html

cd /var/www/html

# remove all the wordpress files if there is something from the volumes to install it again
rm -rf *

# The commands are for installing and using the WP-CLI tool.

# downloads the WP-CLI PHAR (PHP Archive) file from the GitHub repository. The -O flag tells curl to save the file 
with the same name as it has on the server.
curl -O https://raw.githubusercontent.com/wp-cli/builds/gh-pages/phar/wp-cli.phar 

# makes the WP-CLI PHAR file executable.
chmod +x wp-cli.phar 

# moves the WP-CLI PHAR file to the /usr/local/bin directory, which is in the system's PATH, and renames it to wp. 
This allows you to run the wp command from any directory
mv wp-cli.phar /usr/local/bin/wp

# downloads the latest version of WordPress to the current directory. 
The --allow-root flag allows the command to be run as the root user, which is necessary 
if you are logged in as the root user or if you are using WP-CLI with a system-level installation of WordPress.
wp core download --allow-root

mv /var/www/html/wp-config-sample.php /var/www/html/wp-config.php

# change the those lines in wp-config.php file to connect with database

#line 23
sed -i -r "s/database/$db_name/1"   wp-config.php
#line 26
sed -i -r "s/database_user/$db_user/1"  wp-config.php
#line 29
sed -i -r "s/passwod/$db_pwd/1"    wp-config.php

#line 32
sed -i -r "s/localhost/mariadb/1"    wp-config.php  (to connect with mariadb database)

# installs WordPress and sets up the basic configuration for the site. The --url option specifies the URL of the site, 
--title sets the site's title, --admin_user and --admin_password set the username and password for the site's administrator account, 
and --admin_email sets the email address for the administrator. The --skip-email flag prevents WP-CLI from sending an email 
to the administrator with the login details.
wp core install --url=$DOMAIN_NAME/ --title=$WP_TITLE --admin_user=$WP_ADMIN_USR --admin_password=$WP_ADMIN_PWD --admin_email=$WP_ADMIN_EMAIL --skip-email --allow-root

# creates a new user account with the specified username, email address, and password. 
The --role option sets the user's role to author, which gives the user the ability to publish and manage their own posts.
wp user create $WP_USR $WP_EMAIL --role=author --user_pass=$WP_PWD --allow-root

# installs the Astra theme and activates it for the site. The --activate flag tells WP-CLI to make the theme the active theme for the site.
wp theme install astra --activate --allow-root


wp plugin install redis-cache --activate --allow-root


# uses the sed command to modify the www.conf file in the /etc/php/7.3/fpm/pool.d directory. 
The s/listen = \/run\/php\/php7.3-fpm.sock/listen = 9000/g command substitutes the value 9000 for /run/php/php7.3-fpm.sock throughout the file. 
This changes the socket that PHP-FPM listens on from a Unix domain socket to a TCP port.
sed -i 's/listen = \/run\/php\/php7.3-fpm.sock/listen = 9000/g' /etc/php/7.3/fpm/pool.d/www.conf

# creates the /run/php directory, which is used by PHP-FPM to store Unix domain sockets.
mkdir /run/php


wp redis enable --allow-root


# starts the PHP-FPM service in the foreground. The -F flag tells PHP-FPM to run in the foreground, rather than as a daemon in the background.
/usr/sbin/php-fpm7.3 -F

Nginx em

O NGINX é um servidor web que também pode ser usado como proxy reverso, balanceador de carga e cache HTTP. 
É conhecida por seu alto desempenho, estabilidade e baixo consumo de recursos. 
O NGINX é frequentemente usado para lidar com solicitações do lado do servidor para aplicativos da Web 
e também pode ser usado para veicular conteúdo estático, como imagens e arquivos JavaScript. 
Além de seus recursos de servidor web, o NGINX pode ser configurado para lidar com outros tipos de protocolos de rede, 
como Secure Sockets Layer (SSL) e Transport Layer Security (TLS). 
É frequentemente usado em conjunto com outros softwares, como bancos de dados e sistemas de gerenciamento de conteúdo, 
para criar aplicativos web robustos e escaláveis.

    Antes de mergulharmos na peça de instalação, você precisa saber sobre o TLSv1.2 ou o TLSv1.3 porque é bastante importando no nosso caso.

TLS (segurança da camada de transporte)

O Transport Layer Security (TLS) é um protocolo de segurança usado para estabelecer uma comunicação segura entre duas partes na internet. 
Ele é projetado para evitar escutas, adulteração e falsificação de mensagens e para fornecer autenticidade e integridade para dados transmitidos. 
O TLS é usado para proteger uma ampla gama de aplicativos baseados na Internet, incluindo navegação na web, e-mail, 
transferência de arquivos, redes privadas virtuais (VPNs) e sistemas de comunicação em tempo real.

O TLS funciona usando criptografia de chave pública para estabelecer uma conexão segura entre duas partes. 
Quando um cliente quer se comunicar com um servidor usando o TLS, o cliente e o servidor trocam uma série de mensagens 
para estabelecer uma conexão segura. Este processo inclui a troca de certificados digitais e a negociação de chaves de encriptação. 
Uma vez que a conexão é estabelecida, o cliente e o servidor podem se comunicar com segurança pela Internet.

O TLS é o sucessor do protocolo Secure Sockets Layer (SSL), desenvolvido na década de 1990. O TLS é baseado em SSL, mas foi atualizado 
para resolver uma série de vulnerabilidades de segurança que foram descobertas em SSL. O TLS é agora o padrão de fato 
para comunicação segura na Internet e é usado por milhões de sites e aplicativos para proteger dados confidenciais.
OpenSSL (Fos:)

O OpenSSL é uma implementação de código aberto dos protocolos Secure Sockets Layer (SSL) e Transport Layer Security (TLS). 
É uma ferramenta amplamente utilizada para trabalhar com SSL e TLS, e está disponível para a maioria dos sistemas operacionais.

O OpenSSL pode ser usado para uma variedade de tarefas relacionadas ao SSL e TLS, incluindo:

    Criar e gerenciar certificados SSL/TLS e chaves privadas
    Configurar e configurar servidores habilitados para SSL/TLS
    Conectando-se a servidores habilitados para SSL/TLS como cliente
    Depuração de conexões SSL/TLS
    Gerar e assinar certificados digitais

O OpenSSL é frequentemente usado por administradores de sistemas e desenvolvedores para proteger a comunicação entre servidores e clientes, 
ou para criar túneis seguros para transmissão de dados pela Internet. 
Ele também é usado para criar conexões seguras e criptografadas para e-mail, transferência de arquivos e outros tipos de comunicação na Internet.

    Parte da instalação:

    puxar debian:buster(A nossa imagem base)
    atualizar o nosso gerenciador de pacotes apt update -y& & & apt upgrade -y
    apt install -y nginx& & & apt install openssl -yirá instalar o servidor web NGINX e a ferramenta OpenSSL.
    openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/nginx-selfsigned.key -out /etc/ssl/certs/nginx-selfsigned.crt -subj "/C=MO/L=KH/O=1337/OU=student/CN=[sahafid.1337.ma](http://sahafid.42.ma/)"

Este comando gera um certificado SSL/TLS auto-assinado e uma chave privada usando o OpenSSL.

O que é reqO comando é usado para gerar uma solicitação de assinatura de certificado (CSR) ou um certificado auto-assinado. 
O que é -x509A opção diz ao OpenSSL para gerar um certificado autoassinado em vez de um CSR.

O que é -nodesA opção diz ao OpenSSL para não criptografar a chave privada com uma senha. 
Isso significa que a chave privada não será protegida por uma senha e será armazenada em texto simples. 
Isso geralmente não é recomendado para ambientes de produção, pois pode tornar a chave mais vulnerável ao acesso não autorizado.

O que é -daysOpção especifica o número de dias para os quais o certificado deve ser válido. 
Neste caso, o certificado será válido por 365 dias (um ano).

O que é -newkeyOpção especifica que uma nova chave privada deve ser gerada. 
O que é rsa:2048O argumento diz ao OpenSSL para gerar uma chave RSA com um comprimento de 2048 bits.

O que é -keyoutopção especifica o arquivo onde a chave privada deve ser armazenada, 
e o -outA opção especifica o ficheiro onde o certificado deve ser armazenado.

O que é -subjA opção especifica o assunto do certificado. 
O assunto inclui informações sobre a organização para as quais o certificado será usado, 
bem como informações sobre o servidor onde o certificado será instalado. 
Neste caso, o sujeito inclui o país (C-MO), a localização (L-KH), a organização (O 1337), a unidade organizacional (OU-student) 
e o nome comum (CN-sahafid.42.ma).

Depois de executar este comando, um certificado SSL/TLS auto-assinado e uma chave privada serão gerados 
e armazenados nos arquivos especificados. Em seguida, você pode usar esses arquivos para configurar um servidor NGINX 
para usar criptografia SSL/TLS. Tenha em mente que os certificados auto-assinados não são confiáveis pela maioria dos navegadores da Web, 
portanto, você normalmente precisará obter um certificado de uma autoridade de certificação confiável (CA) para uso em um ambiente de produção.

server {

# The server listens for incoming connections on port 443, which is the default port for HTTPS traffic. 
The server listens for both IPv4 and IPv6 connections
	listen 443 ssl;
	listen [::]:443 ssl;

# replace login with your own loggin
	server_name www.login.42.fr login.42.fr;

# The ssl_certificate and ssl_certificate_key directives specify the locations of the SSL/TLS certificate and private key, 
respectively, that will be used to encrypt the traffic. The ssl_protocols directive specifies the TLS protocols that the server should support.
	ssl_certificate /etc/ssl/certs/nginx-selfsigned.crt;
	ssl_certificate_key /etc/ssl/private/nginx-selfsigned.key;

# We are using version 1.3 of TLS
	ssl_protocols TLSv1.3;

# The index directive specifies the default file that should be served when a client requests a directory on the server. 
The root directive specifies the root directory that should be used to search for files.
	index index.php;
	root /var/www/html;

# The location directive defines a block of configuration that applies to a specific location, which is specified using 
a regular expression. In this case, the regular expression ~ [^/]\\.php(/|$) matches any request that ends in .php and is not preceded by a / character.

	location ~ [^/]\\.php(/|$) {

# The try_files directive attempts to serve the requested file, and if it does not exist, it will return a 404 error.
        try_files $uri =404;

#The fastcgi_pass directive passes the request to a FastCGI server for processing.
        fastcgi_pass wordpress:9000;

	# The include directive includes a file with FastCGI parameters.
        include fastcgi_params;

#The fastcgi_param directive sets a FastCGI parameter. The SCRIPT_FILENAME parameter specifies the path to the PHP script that should be executed.
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    }

}

a versão limpa ?

server {
	listen 443 ssl;
	listen [::]:443 ssl;

	server_name www.login.1337.ma login.1337.ma;

	ssl_certificate /etc/ssl/certs/nginx-selfsigned.crt;
	ssl_certificate_key /etc/ssl/private/nginx-selfsigned.key;

	ssl_protocols TLSv1.3;

	index index.php;
	root /var/www/html;

	location ~ [^/]\\.php(/|$) {
        try_files $uri =404;
        fastcgi_pass wordpress:9000;
        include fastcgi_params;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    }
}

você vai copiar esta configuração para este arquivo /etc/nginx/sites-available/default

para manter o contêiner em execução, você deve usar este comando nginx -g daemon off;

O que é nginx -g daemon off;O comando é usado para iniciar o servidor web Nginx no primeiro plano e para desativar o modo daemon.

Em Nginx, o daemonA diretiva é usada para ativar ou desativar o modo daemon, que determina como o processo Nginx é executado. 
Quando o modo daemon está ativado, o processo Nginx é executado em segundo plano e se destaca do terminal. 
Quando o modo daemon está desativado, o processo Nginx é executado em primeiro plano e permanece conectado ao terminal.









PART BONUS
Administrador

O administrador é uma ferramenta para gerenciar sistemas de banco de dados. 
É um único arquivo PHP que fornece uma interface amigável para trabalhar com bancos de dados. 
Com o Adminer, você pode criar e soltar bancos de dados, criar, copiar, alterar e soltar tabelas, excluir, 
editar e adicionar campos, executar qualquer comando SQL e gerenciar usuários e permissões. 
O administrador suporta uma ampla gama de sistemas de banco de dados, incluindo MySQL, MariaDB, PostgreSQL, SQLite, Oracle e MS SQL. 
É um software de código aberto que pode ser usado em qualquer servidor com PHP instalado.

    Parte da instalação:

    puxar debian:buster(A nossa imagem base)
    atualizar o nosso gerenciador de pacotes apt update -y
    apt install wget -y& & & apt-get install php php-mysql -y

    O que é wgetO pacote é um utilitário para baixar arquivos da internet.
    PHP é uma linguagem de programação que é frequentemente usada para desenvolver aplicações web dinâmicas. 
    O módulo PHP MySQL permite que o PHP se comunique com bancos de dados MySQL. 
    Depois de executar este comando, você terá o software necessário instalado para executar um aplicativo web PHP 
    que interage com um banco de dados MySQL.

FTP (Protocolo de Transferência de Arquivos)

File Transfer Protocol (FTP) é um protocolo de rede padrão usado para transferir arquivos de um host para outro através 
de uma rede baseada em TCP, como a internet. O FTP é construído em uma arquitetura cliente-servidor e usa controle separado 
e conexões de dados entre o cliente e o servidor.

O protocolo FTP permite que os clientes façam upload e download de arquivos, criem e excluam diretórios e listem o conteúdo 
dos diretórios em um servidor remoto. Os clientes de FTP estão disponíveis para todos os principais sistemas operacionais, 
e a maioria dos navegadores modernos também suporta FTP.
Diferença entre o modo ativo e passivo Conexões

No FTP, existem dois modos de transferência de dados: ativo e passivo. 
No modo ativo, o cliente inicia uma conexão com o servidor para transferir dados. 
No modo passivo, o cliente inicia uma conexão com o servidor para solicitar uma transferência de dados e, 
em seguida, inicia uma conexão de volta ao cliente para enviar os dados.

O modo passivo é frequentemente usado quando o cliente está atrás de um dispositivo de firewall ou NAT (Network Address Translation), 
porque o firewall ou o NAT do cliente podem bloquear as conexões de entrada do servidor. 
O modo passivo permite que o cliente estabeleça a conexão com o servidor e, em seguida, o servidor pode estabelecer 
uma conexão de volta ao cliente para enviar dados.

    Parte da instalação:

    puxar debian:buster(A nossa imagem base)
    atualizar o nosso gerenciador de pacotes apt update -y
    apt install vsftpd -y

vsftpdpacote em seu sistema. vsftpdsignifica "Very Secure FTP Daemon", e é um popular software de servidor FTP 
para sistemas semelhantes a Unix. Uma vez instalado, você pode usar vsftpdpara configurar e gerenciar um servidor FTP em seu sistema.

    script parte:

#!/bin/bash

service vsftpd start

# Add the USER, change his password and declare him as the owner of wordpress folder and all subfolders

adduser $ftp_user --disabled-password

echo "$ftp_user:$ftp_pwd" | /usr/sbin/chpasswd &> /dev/null

echo "$ftp_user" | tee -a /etc/vsftpd.userlist &> /dev/null

mkdir /home/$ftp_user/ftp

chown nobody:nogroup /home/$ftp_user/ftp
chmod a-w /home/$ftp_user/ftp

mkdir /home/$ftp_user/ftp/files
chown $ftp_user:$ftp_user /home/$ftp_user/ftp/files

sed -i -r "s/#write_enable=YES/write_enable=YES/1"   /etc/vsftpd.conf
sed -i -r "s/#chroot_local_user=YES/chroot_local_user=YES/1"   /etc/vsftpd.conf

echo "
local_enable=YES
allow_writeable_chroot=YES
pasv_enable=YES
local_root=/home/sami/ftp
pasv_min_port=40000
pasv_max_port=40005
userlist_file=/etc/vsftpd.userlist" >> /etc/vsftpd.conf

service vsftpd stop

/usr/sbin/vsftpd

    O script inicia o vsftpdO serviço usando o service- Comando.
    Ele adiciona um novo usuário usando o addusercomando, com o nome de usuário especificado pelo $ftp_uservariável. 
    O que é -disabled-passwordsinaliza que o usuário não deve conseguir fazer login usando uma senha.
    O script então define a senha para o usuário para o valor especificado pelo $ftp_pwdvariável.
    Ele adiciona o nome de usuário do novo usuário ao /etc/vsftpd.userlistarquivo, 
    que é usado por vsftpdpara especificar quais usuários podem fazer login no servidor FTP.
    O script cria um novo diretório em /home/$ftp_user/ftpe coloca o proprietário para nobody:nogroup- A . (í a , , , , , í , . 
    Em seguida, ele define as permissões neste diretório para que ele não seja gravável.
    O script cria outro diretório em /home/$ftp_user/ftp/filese coloca o proprietário para $ftp_user:$ftp_user- A . (í a , , ,
    Ele modifica o /etc/vsftpd.confarquivar para habilitar a escrita e chroot (ou seja, a prisão) para os usuários locais, 
    e para habilitar o modo passivo e especificar o intervalo de portas para usar para conexões de modo passivo.
    local_enable=YES: Esta diretiva diz vsftpdpara permitir que usuários locais façam login no servidor FTP.
    allow_writeable_chroot=YES: Esta diretiva diz vsftpdpara permitir que os usuários locais tenham acesso de gravação aos seus diretórios de casa.
    pasv_enable=YES: Esta diretiva diz vsftpdpara permitir conexões de modo passivo.
    Esta local_root=/home/sami/ftpdiretiva especifica o diretório raiz para usuários locais. 
    Todos os usuários locais serão presos (ou seja, restrito) a este diretório e seus subdiretórios.
    pasv_min_portE a pasv_max_portEssas diretivas especificam o intervalo de portas que o servidor p
    ode usar para estabelecer uma conexão de volta ao cliente quando em modo passivo.
    Esta userlist_file=/etc/vsftpd.userlistdiretiva especifica o arquivo que contém a lista de usuários que estão autorizados a fazer login no FTP.
    O script pára o vsftpdserviço e começar novamente usando o /usr/sbin/vsftpd- Comando.

Cache de REDIS

Redis é um armazenamento de estrutura de dados na memória que pode ser usado como um banco de dados, cache e corretor de mensagens. 
Ele suporta uma variedade de estruturas de dados, como strings, hashes, listas, conjuntos e muito mais. 
Uma das principais características do Redis é a sua capacidade de armazenar dados em cache na memória, 
o que lhe permite alcançar velocidades de leitura e gravação muito rápidas. 
O Redis pode ser usado para melhorar o desempenho de aplicativos da Web, reduzindo o tempo necessário para acessar dados de um banco de dados 
ou de outra camada de armazenamento lento. 
Além de seus recursos de cache, a Redis também oferece mensagens de publicação/assin em cache, 
transações e suporte para várias estruturas de dados, tornando-a uma ferramenta versátil para uma variedade de casos de uso.

    Parte da instalação:

    puxar debian:buster(A nossa imagem base)
    atualizar o nosso gerenciador de pacotes apt update -y

echo "maxmemory 256mb" >> /etc/redis/redis.conf
echo "maxmemory-policy allkeys-lru" >> /etc/redis/redis.conf
sed -i -r "s/bind 127.0.0.1/#bind 127.0.0.0/" /etc/redis/redis.conf

Esses comandos instalarão o servidor Redis em seu sistema e o configurarão para usar um máximo de 256MB de memória. 
A diretiva "máxima memória" define a quantidade máxima de memória que o Redis pode usar. 
A diretiva "Política de Maxemória" especifica a política que a Redis deve usar quando o limite máximo de memória foi atingido. 
Neste caso, a política "allkeys-lru" fará com que a Redis remova as chaves menos usadas recentemente para liberar a memória.

É importante definir cuidadosamente o limite máximo de memória para a instância do Redis, pois o uso excessivo de memória 
pode causar problemas de desempenho ou até mesmo travar o sistema. 
Você também deve considerar o tipo de carga de trabalho que sua instância Redis estará manipulando, 
pois diferentes cargas de trabalho podem ter requisitos de memória diferentes.

para o último comando Este comando modifica o redis.confArquivo de configuração e comentários para fora binddiretiva, 
que especifica o endereço IP que o servidor Redis deve ouvir. Ao comentar esta diretiva, o servidor Redis ouvirá 
todas as interfaces de rede disponíveis.

para manter a redis CMD ["redis-server", "--protected-mode", "no"]

O que é redis-serverO comando é usado para iniciar o servidor Redis, que é um armazenamento de valor de chave 
persistente que pode ser usado para armazenar estruturas de dados, como strings, hashes, listas e conjuntos.

O que é --protected-modeOpção especifica se o servidor Redis deve ser executado em modo protegido ou não. 
O modo protegido é um recurso de segurança que foi introduzido no Redis versão 4.0. 
Ele impede que o servidor Redis aceite conexões de clientes que não estão sendo executados no mesmo host que o servidor.

Especificando o noArgumento, o --protected-modeA opção desabilita o modo protegido e permite que o servidor Redis 
aceite conexões de clientes em execução em qualquer host.

e adicione essas linhas para wp-config.php

define( 'WP_REDIS_HOST', 'redis'); define( 'WP_REDIS_PORT', 6379); definir('WP_CACHE', true);
CADVISOR (serviço extra)

O cAdvisor (abreviação de Container) é uma ferramenta de código aberto desenvolvida pelo Google 
para monitorar e analisar o uso de recursos e o desempenho dos contêineres. Ele fornece informações 
sobre o uso de recursos de contêineres individuais, bem como o uso de recursos da própria máquina host.

O cAdvisor é executado como um daemon na máquina host e coleta dados de uso e desempenho de recursos do sistema operacional 
e contêineres individuais. Ele expõe esses dados por meio de uma interface baseada na Web e de um conjunto de APIs RESTful, 
permitindo que você monitore e analise o uso de recursos de seus contêineres em tempo real.

O cAdvisor é particularmente útil para monitorar e otimizar o desempenho de aplicações em contêineres em um ambiente de produção. 
Ele pode ajudá-lo a identificar restrições de recursos, solucionar problemas e otimizar a alocação de recursos para melhorar 
o desempenho de seus contêineres.

    Parte da instalação:

    puxar debian:buster(A nossa imagem base)
    atualizar o nosso gerenciador de pacotes apt update -y
    apt install wget -y(Ao que aproe ( aproe--, aproe-se, a mesma (proa) apro-C, a wgetpacote, que é um utilitário para baixar arquivos da web.)
    wget [https://github.com/google/cadvisor/releases/download/v0.37.0/cadvisor]
    (https://github.com/google/cadvisor/releases/download/v0.37.0/cadvisor)(download cadvisor do gihub)
    chmod +x cadvisorAlterar a permissão para o executável
    por último, mas não menos importante, execute o executável ./cadvisore você pode encontrar as estatísticas no site.

Nota:

Certifique-se de expor a porta 8080 no arquivo docker-compose e também conectar os volumes certos que você pode ver como no arquivo docker-compose up



/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////




O arquivo docker-compose.yml é usado pelo Docker Compose para definir e gerenciar vários contêineres Docker em um ambiente multi-conteiner. 
Ele permite que você configure e execute aplicações distribuídas de forma simples, especificando como cada contêiner (ou serviço) deve ser configurado e executado, 
incluindo redes, volumes e dependências entre os contêineres. 

Aqui estão os principais componentes e conceitos que geralmente aparecem no arquivo docker-compose.yml:


Estrutura básica

version: '3'
services:
  web:
    image: nginx:latest
    ports:
      - "8080:80"
    volumes:
      - ./html:/usr/share/nginx/html
    networks:
      - my-network

  database:
    image: postgres:alpine
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - my-network

networks:
  my-network:

volumes:
  db-data:
Explicação:


version: Define a versão do formato do Docker Compose. A mais comum é 3, mas pode variar dependendo da compatibilidade que você deseja.
services: Define os diferentes serviços ou contêineres que compõem a sua aplicação.
web: Nome do serviço (pode ser qualquer nome).
image: A imagem Docker que será usada para este contêiner. Neste exemplo, estamos usando nginx:latest.
ports: Mapeamento de portas. Neste caso, a porta 8080 da máquina host será mapeada para a porta 80 do contêiner.
volumes: Monta diretórios do host dentro do contêiner. Aqui, estamos mapeando o diretório ./html para o diretório /usr/share/nginx/html no contêiner.
networks: Define as redes em que este serviço está inserido. Serviços na mesma rede podem se comunicar.
database: Um segundo serviço que usa a imagem postgres:alpine.
environment: Define variáveis de ambiente, como usuário e senha do PostgreSQL.
volumes: Monta um volume persistente para armazenar os dados do banco de dados, permitindo que os dados sobrevivam ao reinício do contêiner.
networks: Define redes personalizadas para que os contêineres possam se comunicar.
volumes: Define volumes persistentes que podem ser usados pelos contêineres.
Benefícios do Docker Compose:
Automatiza a configuração de múltiplos contêineres.
Isolamento: Cada serviço roda em seu próprio contêiner.
Escalabilidade: Fácil de escalar serviços com o comando docker-compose up --scale.
Ambientes replicáveis: Facilita a criação de ambientes consistentes para desenvolvimento, teste e produção.





Exemplo pratico:

Aqui estão alguns exemplos de arquivos docker-compose.yml com diferentes configurações, 
dependendo do tipo de aplicação e do que você deseja implementar:

1. Exemplo básico: Aplicação com NGINX e PostgreSQL
Esse exemplo configura um servidor web (NGINX) e um banco de dados (PostgreSQL).

version: '3'
services:
  web:
    image: nginx:latest
    ports:
      - "8080:80"
    volumes:
      - ./html:/usr/share/nginx/html
    networks:
      - app-network

  database:
    image: postgres:alpine
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - app-network

networks:
  app-network:

volumes:
  db-data:

Esse arquivo define dois serviços:

web: Um servidor NGINX que serve conteúdo da pasta ./html.
database: Um banco de dados PostgreSQL, onde as credenciais são configuradas com variáveis de ambiente.
Ambos os serviços compartilham uma rede chamada app-network para se comunicarem entre si.
O volume db-data garante que os dados do PostgreSQL sejam persistentes mesmo se o contêiner for removido.






2. Exemplo com aplicação Node.js e MongoDB
Esse exemplo é útil para uma aplicação Node.js que se conecta a um banco de dados MongoDB.


version: '3'
services:
  nodeapp:
    image: node:14
    working_dir: /app
    volumes:
      - ./app:/app
    command: npm start
    ports:
      - "3000:3000"
    depends_on:
      - mongo
    networks:
      - app-network

  mongo:
    image: mongo:4.2
    volumes:
      - mongo-data:/data/db
    networks:
      - app-network

networks:
  app-network:

volumes:
  mongo-data:


nodeapp: Um serviço que executa uma aplicação Node.js. O código da aplicação está na pasta local ./app, que é montada no contêiner.
mongo: Um serviço que usa o MongoDB, com armazenamento persistente configurado no volume mongo-data.
depends_on: Isso garante que o serviço mongo seja iniciado antes do nodeapp, pois a aplicação depende do banco de dados.









3. Exemplo de WordPress e MySQL
Esse é um exemplo para rodar o WordPress com um banco de dados MySQL.


version: '3.1'
services:
  wordpress:
    image: wordpress:latest
    ports:
      - "8000:80"
    environment:
      WORDPRESS_DB_HOST: db
      WORDPRESS_DB_USER: exampleuser
      WORDPRESS_DB_PASSWORD: examplepass
      WORDPRESS_DB_NAME: exampledb
    volumes:
      - wordpress-data:/var/www/html
    depends_on:
      - db
    networks:
      - app-network

  db:
    image: mysql:5.7
    environment:
      MYSQL_DATABASE: exampledb
      MYSQL_USER: exampleuser
      MYSQL_PASSWORD: examplepass
      MYSQL_ROOT_PASSWORD: rootpassword
    volumes:
      - db-data:/var/lib/mysql
    networks:
      - app-network

networks:
  app-network:

volumes:
  wordpress-data:
  db-data:



wordpress: Executa a última versão do WordPress. Conecta-se ao banco de dados MySQL, cujas credenciais são passadas como variáveis de ambiente.
db: Um banco de dados MySQL que armazena os dados da aplicação WordPress.
Usa a rede app-network para permitir a comunicação entre os serviços.
Os volumes wordpress-data e db-data garantem que os dados sejam persistentes.
4. Exemplo com Redis e aplicação Python Flask
Esse exemplo mostra como rodar uma aplicação Flask (Python) que se conecta a um cache Redis.





version: '3'
services:
  flask-app:
    build: ./flask-app
    ports:
      - "5000:5000"
    volumes:
      - ./flask-app:/app
    depends_on:
      - redis
    networks:
      - app-network

  redis:
    image: redis:alpine
    networks:
      - app-network

networks:
  app-network:



flask-app: Define um serviço que constrói uma aplicação Flask a partir do diretório ./flask-app. O código da aplicação é montado no contêiner.
redis: Um serviço que usa a imagem Redis para ser usado como cache pela aplicação Flask.
depends_on: Garante que o Redis seja iniciado antes da aplicação Flask.











5. Exemplo com múltiplas instâncias de um serviço (escalabilidade)
Se você quiser escalar um serviço (por exemplo, executar várias instâncias de um servidor web), você pode usar a opção scale.


version: '3'
services:
  web:
    image: nginx:latest
    ports:
      - "8080:80"
    networks:
      - app-network
    deploy:
      replicas: 3

networks:
  app-network:


O serviço web terá 3 réplicas (ou contêineres) rodando simultaneamente.
A funcionalidade de deploy.replicas é mais utilizada em cenários de orquestração (como Docker Swarm ou Kubernetes), mas pode ser útil em alguns cenários com Docker Compose também.





Comandos úteis:
Iniciar os serviços: docker-compose up
Iniciar os serviços em segundo plano: docker-compose up -d
Escalar um serviço: docker-compose up --scale <service>=<number>
Parar os serviços: docker-compose down



docs.docker.com



-------------------------------------------------------------------------------------------------------------------------------------------------
https://github.com/Xperaz/inception-42?tab=readme-ov-file:



O que é um LEMP Stack?
Um LEMP Stack é um conjunto de software usado para hospedar sites e aplicativos web. O nome "LEMP" é um acrônimo que representa as tecnologias que fazem parte desse stack:

L: Linux - Sistema operacional
E: Nginx (pronunciado "Engine X") - Servidor web
M: MariaDB - Sistema de banco de dados (um fork do MySQL)
P: PHP - Linguagem de programação para o lado do servidor (server-side scripting language)
Componentes do LEMP Stack:
Linux (L):

O sistema operacional de código aberto que serve de base para todos os outros componentes. Ele é altamente estável, 
seguro e popular para servidores web. Qualquer distribuição Linux pode ser usada, como Ubuntu, CentOS ou Debian.
Nginx (E):

Nginx é um servidor web de alto desempenho, conhecido por sua velocidade e eficiência no gerenciamento de conexões simultâneas. 
Ele serve para entregar conteúdo estático (como arquivos HTML, CSS, imagens, etc.) e também pode funcionar como um proxy reverso para servir 
conteúdo dinâmico gerado por PHP, entre outros.
Diferente de outros servidores web como o Apache, o Nginx utiliza um modelo de evento assíncrono, o que o torna muito eficiente em termos de recursos e escalabilidade.
MariaDB (M):

MariaDB é um sistema de banco de dados relacional de código aberto que armazena os dados de um site ou aplicativo web. É uma bifurcação (fork) do MySQL, 
e é conhecido por ser rápido, seguro e confiável.
Ele é usado para armazenar e recuperar dados, como usuários, postagens, comentários, configurações de sites, etc.
PHP (P):

PHP é uma linguagem de script do lado do servidor que processa as requisições dinâmicas. Por exemplo, quando um usuário envia um formulário, 
o PHP pode processar esses dados, interagir com o banco de dados (MariaDB) e gerar uma página HTML dinâmica.
O Nginx, por si só, não é capaz de processar código PHP diretamente, então normalmente o Nginx trabalha em conjunto com o PHP-FPM (FastCGI Process Manager) 
para gerenciar as execuções do PHP.
Como os Componentes Interagem?
Cada componente do LEMP Stack tem uma função específica e se comunica com os outros para fornecer uma experiência web completa:

Linux é a base sobre a qual todos os outros serviços funcionam.
Nginx recebe as requisições dos usuários e, dependendo do tipo de conteúdo (estático ou dinâmico), pode servir diretamente ou repassar a requisição para o PHP.
PHP processa o código dinâmico, como consultas ao banco de dados, e pode recuperar ou armazenar dados no MariaDB.
MariaDB armazena os dados e os envia de volta para o PHP quando solicitado, permitindo que páginas dinâmicas sejam geradas com base nas informações armazenadas.
Exemplo de Funcionamento:
O usuário acessa um site (por exemplo, www.exemplo.com).
O Nginx recebe a requisição e verifica se é um arquivo estático (por exemplo, uma imagem, HTML ou CSS). Se for um arquivo estático, ele serve diretamente.
Se a requisição for para uma página dinâmica (por exemplo, um post de blog), o Nginx passa a requisição para o PHP-FPM, que executa o código PHP.
O PHP pode fazer consultas ao MariaDB para obter ou armazenar dados (por exemplo, informações de um post de blog ou dados de um formulário).
O PHP gera uma página HTML dinâmica com os dados recuperados do banco de dados e envia essa página de volta ao Nginx, que então entrega a resposta final para o usuário.
Vantagens do LEMP Stack:
Desempenho: Nginx é muito eficiente em gerenciar grandes quantidades de conexões simultâneas.
Flexibilidade: Pode ser usado para uma variedade de sites e aplicações, desde blogs simples até plataformas de e-commerce complexas.
Escalabilidade: O LEMP Stack é fácil de escalar, seja aumentando os recursos do servidor ou distribuindo a carga entre múltiplos servidores.
Custo-benefício: Como tudo é de código aberto, você não precisa pagar por licenças caras.
Resumo:
O LEMP Stack é uma combinação poderosa e popular de tecnologias que permitem a criação e o gerenciamento de sites e aplicativos web. Ele oferece uma solução leve, escalável 
e de alto desempenho, ideal para aqueles que buscam eficiência e flexibilidade.


-----------------------------------------------------------------------------------------------------------------------------------------------------------------

nginx
🔐 SSL / TLS

1. Certificado do Servidor (Server Certificate):
É público: O certificado do servidor contém uma chave pública e outras informações importantes, como o nome do domínio, a autoridade certificadora que emitiu o certificado, as datas de validade, etc.
Enviado para o cliente: Quando um cliente (como um navegador web) se conecta ao servidor usando HTTPS, o servidor envia esse certificado ao cliente como parte do processo de estabelecimento da conexão segura (chamado de handshake).
Autenticação: O cliente usa o certificado para verificar se está realmente se conectando ao servidor correto. O cliente verifica se o certificado foi emitido por uma autoridade certificadora confiável 
e se ele é válido (não expirou, não foi revogado, etc.).

2. Chave Privada (Private Key):
É privada e deve ser mantida em segredo: A chave privada é um arquivo muito importante e deve ser mantido em segredo. Ela é usada para descriptografar 
dados que o cliente envia ao servidor, além de assinar digitalmente o certificado do servidor.
Acessibilidade: A chave privada deve ser armazenada em um arquivo no servidor com permissões restritas, de modo que apenas o processo mestre do Nginx 
(ou o processo que executa o servidor web) tenha acesso a ela. É fundamental que a chave privada seja bem protegida, porque se alguém conseguir acessá-la, 
poderá decifrar o tráfego criptografado entre o servidor e o cliente.
Configuração no Nginx: No arquivo de configuração do Nginx (nginx.conf ou um arquivo de configuração de site específico), é especificado o caminho 
para o arquivo da chave privada usando a diretiva ssl_certificate_key.

Processo de Conexão HTTPS (Handshake SSL/TLS):
Cliente se conecta ao servidor: O navegador (cliente) envia uma solicitação ao servidor, indicando que deseja estabelecer uma conexão segura (HTTPS).
O servidor envia seu certificado: O servidor responde enviando o seu certificado SSL/TLS para o cliente.
O cliente verifica o certificado: O cliente verifica se o certificado é válido (assinado por uma autoridade confiável, data de validade, etc.). 
Se o certificado for válido, o cliente continua o processo.
Troca de chaves: Em alguns tipos de criptografia, o servidor usa sua chave privada para assinar certos dados, permitindo que o cliente gere uma chave secreta compartilhada. 
O cliente envia dados criptografados que só o servidor pode descriptografar usando a chave privada.
Sessão segura estabelecida: Depois que a chave secreta compartilhada é negociada, tanto o servidor quanto o cliente usam essa chave para criptografar 
e descriptografar o resto da comunicação durante a sessão.



Resumo:
O certificado público do servidor é compartilhado com os clientes e serve para autenticar o servidor.
A chave privada é mantida em segredo e apenas o servidor deve ter acesso a ela. O Nginx precisa dessa chave para criptografar e descriptografar 
o tráfego HTTPS de maneira segura.
Se um atacante conseguir acessar a chave privada, ele poderia interceptar e descriptografar a comunicação entre o servidor e o cliente, 
comprometendo a segurança. Por isso, é essencial manter a chave privada bem protegida e restrita.





-----------------------------------------------------------------------------------------------------------------------------------------------------------------




mariadb

1. MariaDB Server e o Diretório de Dados
MariaDB Server é o software responsável por gerenciar o acesso ao diretório de dados do MariaDB. Esse diretório contém todos os bancos de dados e tabelas 
que o servidor de banco de dados usa para armazenar informações.
Quando o MariaDB Server é iniciado, ele começa a ouvir por conexões de rede de programas clientes, ou seja, ele aguarda conexões de clientes 
(como ferramentas ou aplicações) para poder gerenciar o acesso aos bancos de dados em nome desses clientes.


2. mysqld - O Binário do MariaDB Server
mysqld é o binário (o programa executável) que realmente executa o servidor MariaDB. Ele é o componente principal que gerencia as requisições dos clientes, 
faz o processamento de consultas, gerencia transações e manipula os dados dos bancos de dados.
Em resumo: mysqld é o "coração" do servidor MariaDB, o processo principal que faz o servidor funcionar.


3. mysqld_safe - Iniciando o Servidor de Forma Segura
mysqld_safe é uma ferramenta auxiliar que serve para iniciar o servidor mysqld em sistemas Unix/Linux de maneira mais segura.
Ele adiciona funcionalidades de segurança que tornam a operação do servidor mais robusta, como:
Reiniciar o servidor automaticamente se houver algum erro inesperado (por exemplo, se o servidor falhar por algum motivo).
Registrar informações de erro e runtime em um arquivo de log, permitindo que você monitore problemas que ocorreram enquanto o servidor estava rodando.
Então, ao invés de apenas rodar mysqld diretamente, é recomendado usar mysqld_safe para ter essas camadas adicionais de proteção e monitoramento.


4. mysql_install_db - Inicializando o Diretório de Dados
mysql_install_db é um script usado para inicializar o diretório de dados do MariaDB.
Esse script cria as tabelas de sistema necessárias para o funcionamento do servidor, se elas ainda não existirem. As tabelas de sistema são criadas 
no banco de dados chamado mysql, e elas armazenam informações sobre usuários, permissões, e outras configurações do sistema.

Em outras palavras, esse comando configura o ambiente inicial do servidor MariaDB, criando as tabelas essenciais que o servidor precisa para operar corretamente.

Por que isso é importante?

Antes de você poder usar o MariaDB, é necessário inicializar o banco de dados e criar essas tabelas de sistema. 
Isso é feito apenas uma vez na configuração inicial do servidor (geralmente na instalação).


Resumo:


MariaDB Server é responsável por gerenciar o acesso aos bancos de dados e tabelas.
mysqld é o binário que executa o servidor MariaDB.
mysqld_safe é uma forma mais segura de iniciar o servidor, oferecendo reinicialização automática e logs de erros.
mysql_install_db inicializa o diretório de dados do MariaDB e cria as tabelas de sistema necessárias para que o servidor funcione corretamente.
Esses componentes juntos garantem que o MariaDB funcione de maneira eficiente e segura, permitindo que você armazene e gerencie dados de maneira confiável.



-----------------------------------------------------------------------------------------------------------------------------------------------------------------


WordPress


1. WordPress
O WordPress é um sistema de gerenciamento de conteúdo (CMS) amplamente utilizado para criar e gerenciar websites. 
Ele é construído em PHP e usa um banco de dados MySQL (ou MariaDB) para armazenar informações, como posts, páginas, usuários, 
configurações, etc. O WordPress é dinâmico, ou seja, ele gera páginas HTML sob demanda, com base no conteúdo armazenado no banco de dados.



2. SSL Explained
SSL (Secure Sockets Layer) é um protocolo de segurança que cria uma conexão criptografada entre o servidor web e o navegador do cliente, 
garantindo que os dados transferidos entre eles permaneçam privados e seguros. SSL evoluiu para TLS (Transport Layer Security), 
mas o termo SSL ainda é amplamente utilizado.

Como funciona o SSL/TLS?
Criptografia: O SSL/TLS criptografa a comunicação entre o servidor e o cliente (navegador), evitando que terceiros possam interceptar ou modificar os dados.
Autenticação: O SSL também autentica o servidor, garantindo que o cliente está se conectando ao site legítimo, e não a um impostor.
Integridade dos dados: Ele garante que os dados não sejam alterados durante a transmissão.
Quando um site usa HTTPS, significa que a comunicação entre o navegador do usuário e o servidor web é segura e criptografada.



3. PHP-FPM e a Interação com Nginx
O PHP-FPM (PHP-FastCGI Process Manager) é uma maneira eficiente de processar scripts PHP com o Nginx, que não é capaz de processar PHP diretamente como o Apache.

Diferença entre Nginx e Apache:
Apache pode interpretar PHP diretamente através de módulos (como mod_php), mas o Nginx não pode fazer isso. 
O Nginx serve apenas o conteúdo estático (HTML, imagens, etc.), e para processar conteúdo dinâmico como PHP, ele precisa delegar essa tarefa a outro serviço.

Como o PHP-FPM funciona:
Nginx recebe uma requisição HTTP de um cliente (usuário).
Se a requisição for para um arquivo PHP, o Nginx passa a requisição para o PHP-FPM usando o protocolo FastCGI.
PHP-FPM interpreta o código PHP, executa o script e retorna o resultado para o Nginx.
O Nginx, então, envia a resposta para o cliente (usuário).
O PHP-FPM pode ser configurado para escutar requisições por soquetes Unix ou soquetes TCP, sendo o último mais comum em ambientes distribuídos.

O que é FastCGI?
FastCGI é uma versão otimizada do CGI (Common Gateway Interface). Ele resolve algumas das limitações do CGI tradicional, 
que cria um novo processo para cada requisição. O FastCGI usa processos persistentes, o que significa que um processo pode lidar com várias requisições ao longo do tempo, economizando recursos e melhorando a performance.



4. CGI (Common Gateway Interface)
CGI é um padrão que permite a interação entre um servidor web (como Apache ou Nginx) e linguagens de programação como PHP ou Python. 
Quando um cliente solicita uma página dinâmica (por exemplo, um script PHP ou Python), o servidor web não sabe como processá-la diretamente. 
Portanto, ele invoca um interpretador de scripts (PHP, Python, etc.) através do CGI.

Exemplo: Quando você acessa um site WordPress, o Nginx ou Apache não pode processar o código PHP diretamente. 
Ele passa a requisição para o interpretador PHP (via CGI), que executa o script e retorna o resultado ao servidor, que por sua vez o envia para o cliente.

Limitações do CGI:
Processos por requisição: O CGI cria um novo processo para cada requisição. Isso significa que para cada novo pedido, o servidor cria um processo do zero, 
o que pode ser ineficiente e consumir muitos recursos, especialmente em sites com muito tráfego.

Desempenho: Como os processos são criados e destruídos a cada requisição, a performance pode ser afetada quando o servidor precisa lidar com muitas requisições simultâneas.




5. FastCGI: A Evolução do CGI
FastCGI surgiu como uma solução para os problemas de desempenho do CGI tradicional. Ao invés de criar um novo processo para cada requisição, 
o FastCGI permite que um processo persistente seja usado para lidar com múltiplas requisições, o que economiza recursos e melhora a performance do servidor.

Como o FastCGI funciona: Em vez de criar um novo processo para cada requisição, o FastCGI mantém processos em execução e reutiliza-os para lidar 
com várias requisições ao longo do tempo.
Separação do servidor web e PHP: O FastCGI também permite separar o servidor web (Nginx, Apache) do processamento PHP, utilizando uma comunicação 
entre eles via soquetes Unix ou soquetes TCP. Isso é chamado de WAS (Web Application Server), onde o Nginx atua como servidor web e o PHP-FPM como servidor de aplicação.


Resumo:

WordPress é um CMS que usa PHP e MySQL para gerenciar conteúdo dinâmico em sites.

SSL é um protocolo de segurança para criptografar e autenticar as comunicações entre o servidor e o cliente.

PHP-FPM é um gerenciador de processos para PHP que trabalha com o Nginx para processar scripts PHP usando o protocolo FastCGI.

CGI é uma tecnologia mais antiga que criava um novo processo para cada requisição, enquanto FastCGI permite a reutilização de processos, melhorando a performance.

O FastCGI separa o servidor web do processamento PHP, permitindo uma maior escalabilidade e eficiência no manuseio de múltiplas requisições simultâneas.

Isso explica como a infraestrutura de servidor web moderna funciona, especialmente em ambientes que utilizam o Nginx, PHP-FPM e FastCGI para lidar com sites dinâmicos e seguros.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------




INSTALAR UBUNTU MAQUINA VIRTUAL

Para instalar o Ubuntu em uma máquina com Windows usando uma máquina virtual (VM), você pode utilizar softwares como VirtualBox 
ou VMware Workstation Player para criar uma máquina virtual que rodará o Ubuntu dentro do Windows.

Vou te guiar pelo processo usando o VirtualBox, que é gratuito e bastante popular.

Passos para instalar o Ubuntu no Windows usando VirtualBox:

1. Baixar o Ubuntu
Vá até o site oficial do Ubuntu: https://ubuntu.com/download/desktop.
Baixe a imagem ISO mais recente do Ubuntu Desktop. A versão mais comum é a LTS (Long Term Support), que oferece suporte por 5 anos.


2. Instalar o VirtualBox
Acesse o site do VirtualBox: https://www.virtualbox.org/.
Baixe a versão para Windows e instale o VirtualBox seguindo o assistente de instalação.
O VirtualBox também instalará os extensões de rede e drivers necessários para que a VM funcione corretamente.


3. Criar uma nova máquina virtual no VirtualBox
Abrir o VirtualBox.

Criar uma nova máquina virtual:

Clique em "Novo" (ou "New").
No campo "Nome", coloque um nome para sua máquina virtual (por exemplo, "Ubuntu").
Em "Tipo", selecione Linux e em "Versão", selecione Ubuntu (64-bit) (ou a versão apropriada).
Clique em "Próximo".
Alocar memória (RAM):

O Ubuntu requer pelo menos 2 GB de RAM, mas o recomendado é alocar 4 GB ou mais, se sua máquina permitir. Use o controle deslizante para definir a quantidade de memória.
Clique em "Próximo".
Criar um disco rígido virtual:

Selecione a opção "Criar um disco rígido virtual agora" e clique em "Criar".
Escolha o tipo de arquivo de disco rígido. VDI (VirtualBox Disk Image) é o mais comum.
Tamanho dinâmico: Isso significa que o disco aumentará de tamanho conforme você adicionar dados (até o limite que você definir).
Defina o tamanho do disco virtual. Para uma instalação básica do Ubuntu, 20 GB é suficiente, mas você pode aumentar se precisar de mais espaço.
Clique em "Criar".


4. Configurar a máquina virtual
Configurar a unidade de CD/DVD (onde estará o Ubuntu ISO):
Com a máquina virtual selecionada, clique em "Configurações" (ícone de engrenagem).
Vá para a aba "Sistema" e, em "Placa-mãe", verifique se a ordem de inicialização tem o CD/DVD antes do Disco Rígido.
No menu à esquerda, clique em "Armazenamento".
Em "Controladora: IDE", clique em "Vazio" e, ao lado de "Drive Óptico", clique no ícone de disco e selecione "Escolher um arquivo de disco".
Navegue até a ISO do Ubuntu que você baixou anteriormente e selecione-a.
Clique em "OK" para salvar as configurações.


5. Iniciar a instalação do Ubuntu
Iniciar a máquina virtual:
Com a máquina virtual selecionada, clique em "Iniciar".



Instalar o Ubuntu:
A máquina virtual começará a inicializar a partir da ISO do Ubuntu. Quando o menu do instalador aparecer, selecione "Install Ubuntu".
Escolha o idioma e siga as instruções do instalador.

Quando for solicitado, escolha a opção de instalação "Instalar Ubuntu ao lado do Windows" se você desejar criar um sistema dual-boot 
(Ubuntu e Windows na mesma máquina). Caso deseje instalar apenas no VirtualBox, escolha a opção "Instalação normal".

Configurações adicionais:
Escolha seu fuso horário.
Configure seu teclado (geralmente, o layout padrão é o que você usa, como "Português (Brasil)").
Defina um usuário e senha para o Ubuntu.
A instalação começará e pode levar algum tempo. Após a instalação, o sistema solicitará a reinicialização.


6. Finalizar a instalação
Quando o Ubuntu for reiniciado, você verá uma tela inicial pedindo para remover o disco de instalação (ou seja, a ISO montada). 
No VirtualBox, você pode simplesmente desmontar o arquivo ISO em Armazenamento (deixe a unidade vazia).
O Ubuntu irá iniciar e você poderá se logar com as credenciais que criou durante a instalação.


7. Instalar as "Guest Additions" (opcional, mas recomendado)
As Guest Additions são ferramentas que melhoram a integração entre o Ubuntu e o VirtualBox, como a capacidade de compartilhar pastas, 
melhorar o desempenho gráfico e permitir o redimensionamento automático da tela.

Com a máquina virtual do Ubuntu em execução, no menu do VirtualBox, clique em Dispositivos > Inserir imagem de CD dos "Guest Additions".
Siga as instruções no Ubuntu para instalar o software. Você precisará de uma conexão à internet e provavelmente de permissões administrativas (senha do usuário).
Após a instalação, reinicie o Ubuntu.
Agora, você deve ter o Ubuntu rodando em uma máquina virtual no seu sistema Windows, funcionando bem e com uma experiência de usuário aprimorada!

Dicas:

Alocação de Recursos: Certifique-se de que sua máquina física tem recursos suficientes (RAM e CPU) 
para rodar a VM de forma confortável. Se a máquina estiver lenta, considere ajustar a alocação de recursos na configuração do VirtualBox.

Snapshots: O VirtualBox permite que você crie "snapshots", que são basicamente cópias de segurança do estado da VM. 
Isso é útil se você quiser "voltar no tempo" em algum momento.

